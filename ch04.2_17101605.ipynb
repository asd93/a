{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/asd93/a/blob/master/ch04.2_17101605.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 학습\n",
    "#### 학습 : 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
    "#### 손실함수: 신경망 성능의 '나쁨'을 나타내는 지표 (평균제곱오차,교차엔트로피오차)\n",
    "#### 손실함수의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾는다.<br><br>손실함수의 값을 작게 만드는 기법 : 경사법(함수 기울기 활용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ①평균 제곱 오차\n",
    "#### $E=\\frac{1}{2}\\sum_{k}(y_{k}-t_{k})^{2}$<br>$y_{k}$ : 신경망의 출력, $t_{k}$ : 정답 레이블, k : 데이터의 차원 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "#정답은 '2'\n",
    "t=[0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "#예1:'2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y=[0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "print(mean_squared_error(np.array(y),np.array(t)))\n",
    "\n",
    "#예2:'7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y=[0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "print(mean_squared_error(np.array(y),np.array(t)))\n",
    "\n",
    "#예1의 손실함수 출력이 작고 정답 레이블과의 오차도 작으므로 정답에 가깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ②교차 엔트로피 오차\n",
    "#### $E=-\\sum_{k}t_{k}\\log(y_{k})$<br>log : 밑이 e인 자연로그, $y_{k}$ : 신경망의 출력,  $t_{k}$ : 정답 레이블(원-핫인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta=1e-7\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "#정답은 '2'\n",
    "t=[0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "#예1:'2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y=[0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))\n",
    "\n",
    "#예2:'7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y=[0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))\n",
    "\n",
    "#예1의 오차 값이 더 작으므로 평균 제곱 오차의 판단과 일치."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균 손실 함수 \n",
    "#### $E=-\\frac{1}{N}\\sum_{n}\\sum_{k}t_{nk}\\log(y_{nk})$\n",
    "#### 미니배치 학습 : 신경망 학습에서 훈련 데이터로부터 일부만 골라 학습 수행 - 근사치 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(r\"C:\\Users\\이유선\\Desktop\\'▽'\\py\\deep-learning-from-scratch-master\")\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15427, 26248,  8372, 53331, 30742, 17201, 59425,  8541, 16257,\n",
       "       45795])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#미니배치 데이터 꺼내기\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "np.random.choice(60000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#미니배치 배치 데이터 지원하는 교차 엔트로피 오차\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t=t.reshape(1,t.size)\n",
    "        y=y.reshape(1,y.size)\n",
    "        \n",
    "    batch_size=y.shape[0]\n",
    "    return -np.sum(t*np.log(y+1e-7)) / batch_size\n",
    "\n",
    "#정답 레이블이 원-핫인코딩이 아니라 숫자 레이블일때\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t=t.reshape(1,t.size)\n",
    "        y=y.reshape(1,y.size)\n",
    "        \n",
    "    batch_size=y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch.size), t] +1e-7)) / batch_size\n",
    "\n",
    "#원-핫인코딩일때 t=0이면 오차도 0이므로 정답에 해당하는 신경망 출력만으로 오차 계산 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손실함수가 아닌 정확도를 지표로 할 경우 매개변수의 미분이 대부분 0이 되어 가중치 매개변수의 갱신이 멈춤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
